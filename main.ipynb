{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "# import logging\n",
    "# import sys\n",
    "# import openai\n",
    "\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "# openai.log = \"debug\"\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with nodes\n",
    "\n",
    "documents = SimpleDirectoryReader('data').load_data()\n",
    "parser = SimpleNodeParser.from_defaults()\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "index = VectorStoreIndex(nodes)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is this book all about?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/himalaypatel/Documents/HimalayWork/Learning/LlamaIndex/main.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/himalaypatel/Documents/HimalayWork/Learning/LlamaIndex/main.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m documents \u001b[39m=\u001b[39m SimpleDirectoryReader(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mload_data()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/himalaypatel/Documents/HimalayWork/Learning/LlamaIndex/main.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m index \u001b[39m=\u001b[39m VectorStoreIndex\u001b[39m.\u001b[39;49mfrom_documents(documents)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/himalaypatel/Documents/HimalayWork/Learning/LlamaIndex/main.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m query_engine \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39mas_query_engine()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/himalaypatel/Documents/HimalayWork/Learning/LlamaIndex/main.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m response \u001b[39m=\u001b[39m query_engine\u001b[39m.\u001b[39mquery(\u001b[39m\"\u001b[39m\u001b[39mShort Summery of book?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/HimalayWork/Learning/LlamaIndex/env/lib/python3.10/site-packages/llama_index/indices/base.py:102\u001b[0m, in \u001b[0;36mBaseIndex.from_documents\u001b[0;34m(cls, documents, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     docstore\u001b[39m.\u001b[39mset_document_hash(doc\u001b[39m.\u001b[39mget_doc_id(), doc\u001b[39m.\u001b[39mhash)\n\u001b[1;32m     98\u001b[0m nodes \u001b[39m=\u001b[39m service_context\u001b[39m.\u001b[39mnode_parser\u001b[39m.\u001b[39mget_nodes_from_documents(\n\u001b[1;32m     99\u001b[0m     documents, show_progress\u001b[39m=\u001b[39mshow_progress\n\u001b[1;32m    100\u001b[0m )\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    103\u001b[0m     nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[1;32m    104\u001b[0m     storage_context\u001b[39m=\u001b[39;49mstorage_context,\n\u001b[1;32m    105\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context,\n\u001b[1;32m    106\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[1;32m    107\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    108\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/HimalayWork/Learning/LlamaIndex/env/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py:49\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[0;34m(self, nodes, index_struct, service_context, storage_context, use_async, store_nodes_override, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_async \u001b[39m=\u001b[39m use_async\n\u001b[1;32m     48\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_nodes_override \u001b[39m=\u001b[39m store_nodes_override\n\u001b[0;32m---> 49\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     50\u001b[0m     nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[1;32m     51\u001b[0m     index_struct\u001b[39m=\u001b[39;49mindex_struct,\n\u001b[1;32m     52\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context,\n\u001b[1;32m     53\u001b[0m     storage_context\u001b[39m=\u001b[39;49mstorage_context,\n\u001b[1;32m     54\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[1;32m     55\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     56\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/HimalayWork/Learning/LlamaIndex/env/lib/python3.10/site-packages/llama_index/indices/base.py:71\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[0;34m(self, nodes, index_struct, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m index_struct \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[39massert\u001b[39;00m nodes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     index_struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_index_from_nodes(nodes)\n\u001b[1;32m     72\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct \u001b[39m=\u001b[39m index_struct\n\u001b[1;32m     73\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_storage_context\u001b[39m.\u001b[39mindex_store\u001b[39m.\u001b[39madd_index_struct(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct)\n",
      "File \u001b[0;32m~/Documents/HimalayWork/Learning/LlamaIndex/env/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py:238\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_index_from_nodes\u001b[39m(\u001b[39mself\u001b[39m, nodes: Sequence[BaseNode]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m IndexDict:\n\u001b[1;32m    232\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build the index from nodes.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \n\u001b[1;32m    234\u001b[0m \u001b[39m    NOTE: Overrides BaseIndex.build_index_from_nodes.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[39m        VectorStoreIndex only stores nodes in document store\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39m        if vector store does not store text\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_index_from_nodes(nodes)\n",
      "File \u001b[0;32m~/Documents/HimalayWork/Learning/LlamaIndex/env/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py:226\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[0;34m(self, nodes)\u001b[0m\n\u001b[1;32m    224\u001b[0m     run_async_tasks(tasks)\n\u001b[1;32m    225\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 226\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_nodes_to_index(\n\u001b[1;32m    227\u001b[0m         index_struct, nodes, show_progress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_show_progress\n\u001b[1;32m    228\u001b[0m     )\n\u001b[1;32m    229\u001b[0m \u001b[39mreturn\u001b[39;00m index_struct\n",
      "File \u001b[0;32m~/Documents/HimalayWork/Learning/LlamaIndex/env/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py:186\u001b[0m, in \u001b[0;36mVectorStoreIndex._add_nodes_to_index\u001b[0;34m(self, index_struct, nodes, show_progress)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nodes:\n\u001b[1;32m    184\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_node_with_embedding(nodes, show_progress)\n\u001b[1;32m    187\u001b[0m new_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39madd(nodes)\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39mstores_text \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_nodes_override:\n\u001b[1;32m    190\u001b[0m     \u001b[39m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[1;32m    191\u001b[0m     \u001b[39m# we need to add the nodes to the index struct and document store\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/HimalayWork/Learning/LlamaIndex/env/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py:100\u001b[0m, in \u001b[0;36mVectorStoreIndex._get_node_with_embedding\u001b[0;34m(self, nodes, show_progress)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_node_with_embedding\u001b[39m(\n\u001b[1;32m     90\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     91\u001b[0m     nodes: Sequence[BaseNode],\n\u001b[1;32m     92\u001b[0m     show_progress: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     93\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[BaseNode]:\n\u001b[1;32m     94\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get tuples of id, node, and embedding.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \n\u001b[1;32m     96\u001b[0m \u001b[39m    Allows us to store these nodes in a vector store.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39m    Embeddings are called in batches.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     id_to_embed_map \u001b[39m=\u001b[39m embed_nodes(\n\u001b[1;32m    101\u001b[0m         nodes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_service_context\u001b[39m.\u001b[39;49membed_model, show_progress\u001b[39m=\u001b[39;49mshow_progress\n\u001b[1;32m    102\u001b[0m     )\n\u001b[1;32m    104\u001b[0m     results \u001b[39m=\u001b[39m []\n\u001b[1;32m    105\u001b[0m     \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes:\n",
      "File \u001b[0;32m~/Documents/HimalayWork/Learning/LlamaIndex/env/lib/python3.10/site-packages/llama_index/indices/utils.py:136\u001b[0m, in \u001b[0;36membed_nodes\u001b[0;34m(nodes, embed_model, show_progress)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m         id_to_embed_map[node\u001b[39m.\u001b[39mnode_id] \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39membedding\n\u001b[0;32m--> 136\u001b[0m new_embeddings \u001b[39m=\u001b[39m embed_model\u001b[39m.\u001b[39;49mget_text_embedding_batch(\n\u001b[1;32m    137\u001b[0m     texts_to_embed, show_progress\u001b[39m=\u001b[39;49mshow_progress\n\u001b[1;32m    138\u001b[0m )\n\u001b[1;32m    140\u001b[0m \u001b[39mfor\u001b[39;00m new_id, text_embedding \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(ids_to_embed, new_embeddings):\n\u001b[1;32m    141\u001b[0m     id_to_embed_map[new_id] \u001b[39m=\u001b[39m text_embedding\n",
      "File \u001b[0;32m~/Documents/HimalayWork/Learning/LlamaIndex/env/lib/python3.10/site-packages/llama_index/embeddings/base.py:228\u001b[0m, in \u001b[0;36mBaseEmbedding.get_text_embedding_batch\u001b[0;34m(self, texts, show_progress)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m idx \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(texts) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(cur_batch) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_batch_size:\n\u001b[1;32m    223\u001b[0m     \u001b[39m# flush\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mevent(\n\u001b[1;32m    225\u001b[0m         CBEventType\u001b[39m.\u001b[39mEMBEDDING,\n\u001b[1;32m    226\u001b[0m         payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mSERIALIZED: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dict()},\n\u001b[1;32m    227\u001b[0m     ) \u001b[39mas\u001b[39;00m event:\n\u001b[0;32m--> 228\u001b[0m         embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_text_embeddings(cur_batch)\n\u001b[1;32m    229\u001b[0m         result_embeddings\u001b[39m.\u001b[39mextend(embeddings)\n\u001b[1;32m    230\u001b[0m         event\u001b[39m.\u001b[39mon_end(\n\u001b[1;32m    231\u001b[0m             payload\u001b[39m=\u001b[39m{\n\u001b[1;32m    232\u001b[0m                 EventPayload\u001b[39m.\u001b[39mCHUNKS: cur_batch,\n\u001b[1;32m    233\u001b[0m                 EventPayload\u001b[39m.\u001b[39mEMBEDDINGS: embeddings,\n\u001b[1;32m    234\u001b[0m             },\n\u001b[1;32m    235\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/HimalayWork/Learning/LlamaIndex/env/lib/python3.10/site-packages/llama_index/embeddings/openai.py:360\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_text_embeddings\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_text_embeddings\u001b[39m(\u001b[39mself\u001b[39m, texts: List[\u001b[39mstr\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[List[\u001b[39mfloat\u001b[39m]]:\n\u001b[1;32m    354\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get text embeddings.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \n\u001b[1;32m    356\u001b[0m \u001b[39m    By default, this is a wrapper around _get_text_embedding.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[39m    Can be overridden for batch queries.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m     \u001b[39mreturn\u001b[39;00m get_embeddings(\n\u001b[1;32m    361\u001b[0m         texts,\n\u001b[1;32m    362\u001b[0m         engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_text_engine,\n\u001b[1;32m    363\u001b[0m         deployment_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment_name,\n\u001b[1;32m    364\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_all_kwargs,\n\u001b[1;32m    365\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/HimalayWork/Learning/LlamaIndex/env/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/Documents/HimalayWork/Learning/LlamaIndex/env/lib/python3.10/site-packages/tenacity/__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoSleep):\n\u001b[1;32m    388\u001b[0m     retry_state\u001b[39m.\u001b[39mprepare_for_next_attempt()\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msleep(do)\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m do\n",
      "File \u001b[0;32m~/Documents/HimalayWork/Learning/LlamaIndex/env/lib/python3.10/site-packages/tenacity/nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msleep\u001b[39m(seconds: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[39m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     time\u001b[39m.\u001b[39;49msleep(seconds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#without nodes\n",
    "documents = SimpleDirectoryReader('data').load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Short Summery of book?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
